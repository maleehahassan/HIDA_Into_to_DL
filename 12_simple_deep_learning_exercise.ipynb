{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maleehahassan/HIDA_Into_to_DL/blob/main/12_simple_deep_learning_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9f796047e8af30a7"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple Deep Learning with PyTorch (Exercise Version)\n",
        "\n",
        "This notebook implements a basic deep learning model using PyTorch to classify MNIST digits. You'll learn by completing the exercises:\n",
        "- Building a simple neural network\n",
        "- Training and validation process\n",
        "- Performance visualization\n",
        "\n",
        "## Step 1: Import Required Libraries\n",
        "\n",
        "First, import all necessary libraries for our deep learning project."
      ],
      "id": "9f796047e8af30a7"
    },
    {
      "metadata": {
        "id": "9b10cf8f2fbf70d3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# TODO: Import the required PyTorch libraries and other dependencies\n",
        "# Hint: We need torch, torch.nn, torch.optim, torchvision, and matplotlib\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "9b10cf8f2fbf70d3"
    },
    {
      "metadata": {
        "id": "4965459c008a4b0d"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Set Random Seed\n",
        "\n",
        "Setting a random seed ensures reproducible results across different runs."
      ],
      "id": "4965459c008a4b0d"
    },
    {
      "metadata": {
        "id": "728a6c265757a0e3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# TODO: Set a random seed using torch.manual_seed()\n",
        "# Use seed value: 42\n",
        "\n"
      ],
      "id": "728a6c265757a0e3"
    },
    {
      "metadata": {
        "id": "d4fd28398ccc5edb"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define Neural Network Architecture\n",
        "\n",
        "Create a simple neural network for MNIST classification:\n",
        "1. Input layer: 784 neurons (28x28 MNIST images flattened)\n",
        "2. Hidden layer: 128 neurons with ReLU activation\n",
        "3. Output layer: 10 neurons (one for each digit)"
      ],
      "id": "d4fd28398ccc5edb"
    },
    {
      "metadata": {
        "id": "fdf67f92e37cc355"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()  # Flatten the 28x28 image to 784 pixels\n",
        "\n",
        "        # TODO: Complete the neural network architecture using nn.Sequential\n",
        "        # Requirements:\n",
        "        # 1. Linear layer from 784 -> 128\n",
        "        # 2. ReLU activation\n",
        "        # 3. Linear layer from 128 -> 10\n",
        "        self.layers = nn.Sequential(\n",
        "            # Your code here\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement the forward pass\n",
        "        # 1. Flatten the input\n",
        "        # 2. Pass through layers\n",
        "        # Your code here\n",
        "\n"
      ],
      "id": "fdf67f92e37cc355"
    },
    {
      "metadata": {
        "id": "47df4a1cd9c50a3b"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4: Define Training Function\n",
        "\n",
        "The training function is provided. Study it carefully to understand:\n",
        "- How the training loop works\n",
        "- How metrics are calculated\n",
        "- The difference between training and validation phases"
      ],
      "id": "47df4a1cd9c50a3b"
    },
    {
      "metadata": {
        "id": "58bd421a73723c0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            # TODO: Implement the training step\n",
        "            # 1. Forward pass\n",
        "            # 2. Calculate loss\n",
        "            # 3. Zero gradients\n",
        "            # 4. Backward pass\n",
        "            # 5. Optimizer step\n",
        "            # Your code here\n",
        "\n",
        "\n",
        "            # Calculate training statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate and store training metrics\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = 100 * correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = 100 * correct / total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]:')\n",
        "        print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "        print('-' * 60)\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies\n"
      ],
      "id": "58bd421a73723c0"
    },
    {
      "metadata": {
        "id": "4cf8abc20391c156"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5: Define Visualization Function\n",
        "\n",
        "The visualization function is partially provided. Complete the missing parts to create informative plots."
      ],
      "id": "4cf8abc20391c156"
    },
    {
      "metadata": {
        "id": "1e1c4fa13617ac50"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # TODO: Complete the loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    # Your code here: Plot training and validation losses\n",
        "\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # TODO: Complete the accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # Your code here: Plot training and validation accuracies\n",
        "\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "id": "1e1c4fa13617ac50"
    },
    {
      "metadata": {
        "id": "88492b1625e99cd2"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 6: Main Execution Function\n",
        "\n",
        "Complete the main function to orchestrate the training process."
      ],
      "id": "88492b1625e99cd2"
    },
    {
      "metadata": {
        "id": "3000831c634ac61"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def main():\n",
        "    # TODO: Set the hyperparameters\n",
        "    # Your code here: Define batch_size, learning_rate, and num_epochs\n",
        "\n",
        "\n",
        "    # Data preprocessing\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    full_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "\n",
        "    # TODO: Split the dataset into training and validation sets (80% train, 20% validation)\n",
        "    # Your code here\n",
        "\n",
        "\n",
        "    # TODO: Create data loaders\n",
        "    # Your code here: Create train_loader and val_loader\n",
        "\n",
        "\n",
        "    # TODO: Initialize the model, loss function, and optimizer\n",
        "    # Your code here\n",
        "\n",
        "\n",
        "    # Train the model and get metrics\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
        "        model, train_loader, val_loader, criterion, optimizer, num_epochs\n",
        "    )\n",
        "\n",
        "    # Plot the results\n",
        "    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies)\n"
      ],
      "id": "3000831c634ac61"
    },
    {
      "metadata": {
        "id": "636b8e855c5a5090"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 7: Execute Training\n",
        "\n",
        "Run the main function when the script is executed directly."
      ],
      "id": "636b8e855c5a5090"
    },
    {
      "metadata": {
        "id": "e5f8f39e01b8a16d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "id": "e5f8f39e01b8a16d"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}