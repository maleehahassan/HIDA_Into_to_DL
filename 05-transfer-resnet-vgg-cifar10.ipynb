{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Project Overview: CIFAR10 Classification with Transfer Learning (ResNet-50 vs VGG-19)\n",
    "\n",
    "This notebook demonstrates how to use transfer learning for image classification on the CIFAR10 dataset, comparing two powerful pretrained models: ResNet-50 and VGG-19. The workflow includes:\n",
    "\n",
    "- **Importing Libraries**: Essential Python libraries for deep learning, data manipulation, and visualization are imported.\n",
    "- **Loading Data**: The CIFAR10 dataset is loaded, which contains 60,000 color images in 10 classes.\n",
    "- **Preprocessing**: Images are resized to 224x224 pixels to match the input size required by ResNet-50 and VGG-19. Pixel values are normalized to the [0, 1] range.\n",
    "- **Visualization**: 25 sample images from the training set are displayed with their class names for a quick visual check.\n",
    "- **Model Setup**: Two models are built using transfer learning:\n",
    "    - ResNet-50 and VGG-19 are loaded with pretrained weights (from ImageNet), excluding their top layers.\n",
    "    - A new classification head is added to each model for CIFAR10.\n",
    "    - The base models are frozen so only the new layers are trained.\n",
    "- **Training**: Both models are trained on the preprocessed CIFAR10 data for 10 epochs.\n",
    "- **Evaluation**: Training histories are visualized, and both models are evaluated on the test set to compare their accuracy.\n",
    "- **Confusion Matrix**: Confusion matrices are plotted for both models to show how well each class is predicted.\n",
    "- **Summary**: The notebook concludes with a summary, encouraging learners to experiment further.\n",
    "\n",
    "---\n",
    "\n",
    "This workflow teaches how to apply state-of-the-art deep learning architectures to a new dataset, compare their performance, and understand the benefits of transfer learning."
   ],
   "id": "88c070bba9e74b73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ],
   "id": "e22fdfeeebc951aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the CIFAR10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
   ],
   "id": "4c1c0f5752be9d7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Resize images to 224x224 for compatibility with pretrained models\n",
    "IMG_SIZE = 224\n",
    "train_images_resized = tf.image.resize(train_images, [IMG_SIZE, IMG_SIZE]).numpy()\n",
    "test_images_resized = tf.image.resize(test_images, [IMG_SIZE, IMG_SIZE]).numpy()"
   ],
   "id": "71a3b162dba20b02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "train_images_resized = train_images_resized / 255.0\n",
    "test_images_resized = test_images_resized / 255.0"
   ],
   "id": "c4a8a589d7a4e61b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define class names for CIFAR10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ],
   "id": "28011f8f7c74ed"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Display 25 sample images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    img = train_images_resized[i]\n",
    "    # Ensure image is RGB and in [0,1] range\n",
    "    if img.shape[-1] == 3:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[int(train_labels[i,0])])\n",
    "    # Remove colorbar if accidentally added\n",
    "    ax = plt.gca()\n",
    "    for cbar in ax.figure.axes:\n",
    "        if hasattr(cbar, 'colorbar'):\n",
    "            cbar.colorbar.remove()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "aa7d0bf0b8580de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare labels for training (flatten)\n",
    "train_labels_flat = train_labels.flatten()\n",
    "test_labels_flat = test_labels.flatten()"
   ],
   "id": "d8c0de04091ba372"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load ResNet-50 via keras.applications\n",
    "base_resnet = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "# Freeze base model\n",
    "base_resnet.trainable = False\n",
    "# Add classification head\n",
    "resnet_model = keras.Sequential([\n",
    "    base_resnet,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "id": "6abad91a0aee9f01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compile ResNet-50 model\n",
    "resnet_model.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])"
   ],
   "id": "3b3b365c841207b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train ResNet-50 model\n",
    "history_resnet = resnet_model.fit(train_images_resized, train_labels_flat, epochs=10,\n",
    "                                  batch_size=64,\n",
    "                                  validation_data=(test_images_resized, test_labels_flat),\n",
    "                                  verbose=2)"
   ],
   "id": "4ea030d625d5298d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load VGG-19 via keras.applications\n",
    "base_vgg = keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "# Freeze base model\n",
    "base_vgg.trainable = False\n",
    "# Add classification head\n",
    "vgg_model = keras.Sequential([\n",
    "    base_vgg,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "id": "b14f4a979d78a278"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compile VGG model\n",
    "vgg_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ],
   "id": "d1b10e9a1a47899c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train VGG model\n",
    "history_vgg = vgg_model.fit(train_images_resized, train_labels_flat, epochs=10,\n",
    "                            batch_size=64,\n",
    "                            validation_data=(test_images_resized, test_labels_flat),\n",
    "                            verbose=2)"
   ],
   "id": "17784e32fccc8738"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert training histories to DataFrames\n",
    "history_resnet_df = pd.DataFrame(history_resnet.history)\n",
    "history_vgg_df = pd.DataFrame(history_vgg.history)"
   ],
   "id": "e181b8b5ea9fcad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot training and validation accuracy for both models\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=history_resnet_df['val_accuracy'], label='ResNet-50 (val)')\n",
    "sns.lineplot(data=history_vgg_df['val_accuracy'], label='VGG-19 (val)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "dd1303a65583f570"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate both models on the test set\n",
    "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images_resized, test_labels_flat, verbose=2)\n",
    "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_images_resized, test_labels_flat, verbose=2)\n",
    "print(f'ResNet-50 Test Accuracy: {resnet_test_acc:.3f}')\n",
    "print(f'VGG-19 Test Accuracy: {vgg_test_acc:.3f}')"
   ],
   "id": "cdfd2290bd021bae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show confusion matrix for both models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "resnet_pred_labels = np.argmax(resnet_model.predict(test_images_resized), axis=1)\n",
    "vgg_pred_labels = np.argmax(vgg_model.predict(test_images_resized), axis=1)\n",
    "cm_resnet = confusion_matrix(test_labels_flat, resnet_pred_labels)\n",
    "cm_vgg = confusion_matrix(test_labels_flat, vgg_pred_labels)\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(cm_resnet, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('ResNet-50 Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(cm_vgg, annot=True, fmt='d', cmap='Greens', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('VGG-19 Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "2d5718a582f07e1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "This notebook compared the performance of ResNet-50 and VGG-19 on the CIFAR10 dataset using transfer learning. You can see the validation accuracy and confusion matrices for both models above. Try adjusting the number of epochs or unfreezing layers for further improvements.\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Workflow Recap:**\n",
    "\n",
    "- **Importing Libraries**: Essential Python libraries for deep learning, data manipulation, and visualization.\n",
    "- **Loading Data**: CIFAR10 dataset with 60,000 color images in 10 classes.\n",
    "- **Preprocessing**: Resize images to 224x224 pixels and normalize pixel values.\n",
    "- **Visualization**: Display 25 sample images with class names.\n",
    "- **Model Setup**: Build ResNet-50 and VGG-19 models with transfer learning and custom classification heads.\n",
    "- **Training**: Train both models for 10 epochs.\n",
    "- **Evaluation**: Visualize training histories and compare test accuracy.\n",
    "- **Confusion Matrix**: Plot confusion matrices for both models.\n",
    "- **Summary**: Encourage further experimentation.\n",
    "\n",
    "This notebook guides you through applying and comparing state-of-the-art deep learning models on a benchmark dataset, highlighting the power of transfer learning.\n"
   ],
   "id": "5879260dece3c24d"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
