{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Simple Deep Learning with PyTorch (Exercise Version)\n",
    "\n",
    "This notebook implements a basic deep learning model using PyTorch to classify MNIST digits. You'll learn by completing the exercises:\n",
    "- Building a simple neural network\n",
    "- Training and validation process\n",
    "- Performance visualization\n",
    "\n",
    "## Step 1: Import Required Libraries\n",
    "\n",
    "First, import all necessary libraries for our deep learning project."
   ],
   "id": "9f796047e8af30a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Import the required PyTorch libraries and other dependencies\n",
    "# Hint: We need torch, torch.nn, torch.optim, torchvision, and matplotlib\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "9b10cf8f2fbf70d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Set Random Seed\n",
    "\n",
    "Setting a random seed ensures reproducible results across different runs."
   ],
   "id": "4965459c008a4b0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Set a random seed using torch.manual_seed()\n",
    "# Use seed value: 42\n",
    "\n"
   ],
   "id": "728a6c265757a0e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Define Neural Network Architecture\n",
    "\n",
    "Create a simple neural network for MNIST classification:\n",
    "1. Input layer: 784 neurons (28x28 MNIST images flattened)\n",
    "2. Hidden layer: 128 neurons with ReLU activation\n",
    "3. Output layer: 10 neurons (one for each digit)"
   ],
   "id": "d4fd28398ccc5edb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Flatten the 28x28 image to 784 pixels\n",
    "\n",
    "        # TODO: Complete the neural network architecture using nn.Sequential\n",
    "        # Requirements:\n",
    "        # 1. Linear layer from 784 -> 128\n",
    "        # 2. ReLU activation\n",
    "        # 3. Linear layer from 128 -> 10\n",
    "        self.layers = nn.Sequential(\n",
    "            # Your code here\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass\n",
    "        # 1. Flatten the input\n",
    "        # 2. Pass through layers\n",
    "        # Your code here\n",
    "\n"
   ],
   "id": "fdf67f92e37cc355"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Define Training Function\n",
    "\n",
    "The training function is provided. Study it carefully to understand:\n",
    "- How the training loop works\n",
    "- How metrics are calculated\n",
    "- The difference between training and validation phases"
   ],
   "id": "47df4a1cd9c50a3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # TODO: Implement the training step\n",
    "            # 1. Forward pass\n",
    "            # 2. Calculate loss\n",
    "            # 3. Zero gradients\n",
    "            # 4. Backward pass\n",
    "            # 5. Optimizer step\n",
    "            # Your code here\n",
    "\n",
    "\n",
    "            # Calculate training statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate and store training metrics\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]:')\n",
    "        print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        print('-' * 60)\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n"
   ],
   "id": "58bd421a73723c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Define Visualization Function\n",
    "\n",
    "The visualization function is partially provided. Complete the missing parts to create informative plots."
   ],
   "id": "4cf8abc20391c156"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # TODO: Complete the loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Your code here: Plot training and validation losses\n",
    "\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # TODO: Complete the accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Your code here: Plot training and validation accuracies\n",
    "\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "1e1c4fa13617ac50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 6: Main Execution Function\n",
    "\n",
    "Complete the main function to orchestrate the training process."
   ],
   "id": "88492b1625e99cd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main():\n",
    "    # TODO: Set the hyperparameters\n",
    "    # Your code here: Define batch_size, learning_rate, and num_epochs\n",
    "\n",
    "\n",
    "    # Data preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    # Load MNIST dataset\n",
    "    full_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # TODO: Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "    # TODO: Create data loaders\n",
    "    # Your code here: Create train_loader and val_loader\n",
    "\n",
    "\n",
    "    # TODO: Initialize the model, loss function, and optimizer\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "    # Train the model and get metrics\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, num_epochs\n",
    "    )\n",
    "\n",
    "    # Plot the results\n",
    "    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies)\n"
   ],
   "id": "3000831c634ac61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 7: Execute Training\n",
    "\n",
    "Run the main function when the script is executed directly."
   ],
   "id": "636b8e855c5a5090"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "e5f8f39e01b8a16d"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
