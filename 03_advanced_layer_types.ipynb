{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maleehahassan/HIDA_Into_to_DL/blob/main/03_advanced_layer_types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview: Image Classification with Deep Learning\n",
        "\n",
        "In this project, you will explore the fundamentals of image classification using deep learning techniques. The motivation behind this code is to introduce learners to the process of building, training, and evaluating neural networks for computer vision tasks. You will work with the CIFAR10 dataset, a widely used benchmark in machine learning, which contains 60,000 color images in 10 different classes.\n",
        "\n",
        "Throughout the notebook, you will:\n",
        "- Load and preprocess image data for neural network training\n",
        "- Visualize sample images and understand their structure\n",
        "- Build and compare different convolutional neural network (CNN) architectures\n",
        "- Train models and monitor their performance using accuracy and loss metrics\n",
        "- Explore techniques such as pooling and dropout to improve model generalization\n",
        "\n",
        "By the end of this project, you will gain hands-on experience with key concepts in deep learning for image classification, and understand how to apply these methods to real-world datasets."
      ],
      "metadata": {
        "id": "1L6kyINPUkLr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNI3Tm3mQEsU"
      },
      "source": [
        "# image classification\n",
        "\n",
        "We will use the CIFAR10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaqV49EYQbpK"
      },
      "source": [
        "# Import keras from tensorflow for building neural networks\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goq1v4bMROrV"
      },
      "source": [
        "# Check the installed version of keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-LQul5yRP3G"
      },
      "source": [
        "# Load the CIFAR10 dataset and split into training and test sets\n",
        " (train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVOySMxSReME"
      },
      "source": [
        "# Show the shape of the training images array\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkupJYV2Rmsd"
      },
      "source": [
        "# Show the data type of the training images\n",
        "train_images.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQndg7v5RtYN"
      },
      "source": [
        "# Set the number of images to use for training\n",
        "n_images = 5000\n",
        "\n",
        "# Select the first n_images for training\n",
        "train_images = train_images[:n_images]\n",
        "train_labels = train_labels[:n_images]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG-FtyYzSAf2"
      },
      "source": [
        "# Show the new shape of the training images after selection\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7DKcoQ4SE72"
      },
      "source": [
        "# Show the minimum and maximum pixel values in the training images\n",
        "train_images.min(), train_images.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu8-VhK4SKWB"
      },
      "source": [
        "# Show the shape of the training labels\n",
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c16gU8SVSOw0"
      },
      "source": [
        "# Show the minimum and maximum label values\n",
        "train_labels.min(), train_labels.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFigLJxqSTcu"
      },
      "source": [
        "# Show the data type of the training labels\n",
        "train_labels.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jepUthuSSWmm"
      },
      "source": [
        "# Normalize the pixel values to the range [0, 1]\n",
        "train_images = train_images / 255.\n",
        "test_images = test_images / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhzd_KVcSuBt"
      },
      "source": [
        "# Define the class names for the CIFAR10 dataset\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BikN25IiSyUX"
      },
      "source": [
        "# Import matplotlib for image visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure to display 25 sample images\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# Loop through the first 25 images and display them with their class names\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "  plt.axis('off')\n",
        "  plt.title(class_names[train_labels[i,0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGdptc5CTNY7"
      },
      "source": [
        "# Calculate the total number of pixels per image\n",
        "image_dim = train_images.shape[1]*train_images.shape[2]*train_images.shape[3]\n",
        "print(image_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncF90e6cUC2y"
      },
      "source": [
        "![](https://carpentries-incubator.github.io/deep-learning-intro/fig/04_conv_matrix.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYwii3HUKC1"
      },
      "source": [
        "![](https://carpentries-incubator.github.io/deep-learning-intro/fig/04_conv_image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybw8S7w5TpWO"
      },
      "source": [
        "# Define a function to create the first CNN model\n",
        "def create_cnn1():\n",
        "\n",
        "  # Input layer, specifying the shape of the input images\n",
        "  inputs = keras.Input(shape=train_images.shape[1:])\n",
        "\n",
        "  # First convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "  conv1 = keras.layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
        "\n",
        "  # Second convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "  conv2 = keras.layers.Conv2D(32, (3,3), activation='relu')(conv1)\n",
        "\n",
        "  # Flatten the output from the convolutional layers to feed into the dense layer\n",
        "  flat = keras.layers.Flatten()(conv2)\n",
        "\n",
        "  # Output layer with 10 units (one for each class)\n",
        "  outputs = keras.layers.Dense(10)(flat)\n",
        "\n",
        "  # Return the constructed model\n",
        "  return keras.Model(inputs=inputs, outputs=outputs, name=\"cifar_model_small\")\n",
        "\n",
        "# Create an instance of the model\n",
        "model = create_cnn1()\n",
        "\n",
        "# Display the model architecture\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_q8gjImWEx6"
      },
      "source": [
        "# Define a function to create the second CNN model with pooling layers\n",
        "def create_cnn2():\n",
        "\n",
        "  # Input layer, specifying the shape of the input images\n",
        "  inputs = keras.Input(shape=train_images.shape[1:])\n",
        "\n",
        "  # First convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "  conv1 = keras.layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
        "\n",
        "  # First pooling layer (2x2 max pooling)\n",
        "  pool1 = keras.layers.MaxPool2D((2,2))(conv1)\n",
        "\n",
        "  # Second convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "  conv2 = keras.layers.Conv2D(32, (3,3), activation='relu')(pool1)\n",
        "\n",
        "  # Second pooling layer (2x2 max pooling)\n",
        "  pool2 = keras.layers.MaxPool2D((2,2))(conv2)\n",
        "\n",
        "  # Flatten the output from the convolutional layers to feed into the dense layer\n",
        "  flat = keras.layers.Flatten()(pool2)\n",
        "\n",
        "  # Output layer with 10 units (one for each class)\n",
        "  outputs = keras.layers.Dense(10)(flat)\n",
        "\n",
        "  # Return the constructed model\n",
        "  return keras.Model(inputs=inputs, outputs=outputs, name=\"cifar_model_small\")\n",
        "\n",
        "# Create an instance of the model\n",
        "model = create_cnn2()\n",
        "\n",
        "# Display the model architecture\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM0h6HwRXHXX"
      },
      "source": [
        "# Compile the model with Adam optimizer, sparse categorical crossentropy loss, and accuracy metric\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPmXkHYMX5sz"
      },
      "source": [
        "# Train the model on the training data for 10 epochs, with validation on the test data\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFaQT8fTY_uB"
      },
      "source": [
        "# Import seaborn and pandas for data visualization and manipulation\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the training history to a DataFrame for easier plotting\n",
        "history_df = pd.DataFrame.from_dict(history.history)\n",
        "print(history_df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFg5XdWbaUwh"
      },
      "source": [
        "# Plot the training and validation accuracy over epochs\n",
        "sns.lineplot(data=history_df[['accuracy','val_accuracy']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r5ZyWfeadtE"
      },
      "source": [
        "# Plot the training and validation loss over epochs\n",
        "sns.lineplot(data=history_df[['loss','val_loss']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW3JBuhVa6WJ"
      },
      "source": [
        "![](https://carpentries-incubator.github.io/deep-learning-intro/fig/neural_network_sketch_dropout.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn3hCR6danWT"
      },
      "source": [
        "# Define a function to create the third CNN model with dropout\n",
        "def create_cnn3():\n",
        "\n",
        "  # Input layer, specifying the shape of the input images\n",
        "  inputs = keras.Input(shape=train_images.shape[1:])\n",
        "\n",
        "  # First convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "  conv1 = keras.layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
        "\n",
        "  # First pooling layer (2x2 max pooling)\n",
        "  pool1 = keras.layers.MaxPool2D((2,2))(conv1)\n",
        "\n",
        "  # Second convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "  conv2 = keras.layers.Conv2D(32, (3,3), activation='relu')(pool1)\n",
        "\n",
        "  # Second pooling layer (2x2 max pooling)\n",
        "  pool2 = keras.layers.MaxPool2D((2,2))(conv2)\n",
        "\n",
        "  # Dropout layer with 20% rate to reduce overfitting\n",
        "  dropped = keras.layers.Dropout(0.2)(pool2)\n",
        "\n",
        "  # Flatten the output from the convolutional layers to feed into the dense layer\n",
        "  flat = keras.layers.Flatten()(dropped)\n",
        "\n",
        "  # Output layer with 10 units (one for each class)\n",
        "  outputs = keras.layers.Dense(10)(flat)\n",
        "\n",
        "  # Return the constructed model\n",
        "  return keras.Model(inputs=inputs, outputs=outputs, name=\"cifar_model_small_withdropout\")\n",
        "\n",
        "# Create an instance of the model\n",
        "model = create_cnn3()\n",
        "\n",
        "# Display the model architecture\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFE_brrDcAjt"
      },
      "source": [
        "# Compile the model with Adam optimizer, sparse categorical crossentropy loss, and accuracy metric\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5_-sXAScICg"
      },
      "source": [
        "# Train the model on the training data for 10 epochs, with validation on the test data\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN7S9QoycLfu"
      },
      "source": [
        "# Convert the training history to a DataFrame for easier plotting\n",
        "history_df = pd.DataFrame.from_dict(history.history)\n",
        "history_df['epoch'] = range(1,len(history_df)+1)\n",
        "history_df = history_df.set_index('epoch')\n",
        "\n",
        "# Plot the training and validation accuracy over epochs\n",
        "sns.lineplot(data=history_df[['accuracy', 'val_accuracy']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0clOGbqBcffU"
      },
      "source": [
        "# Evaluate the model on the test data and store the loss and accuracy\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4zdsqt-csxn"
      },
      "source": [
        "# Plot the training and validation loss over epochs\n",
        "sns.lineplot(data=history_df[['loss', 'val_loss']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7sLHVc5cxxe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}