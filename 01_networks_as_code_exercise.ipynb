{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maleehahassan/HIDA_Into_to_DL/blob/main/01_networks_as_code_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview: Wine Classification with Neural Networks\n",
        "\n",
        "This notebook demonstrates how to classify wine samples into three categories using a neural network and the classic sklearn wine dataset. The workflow includes:\n",
        "\n",
        "1. **Data Loading & Exploration**: The wine dataset is loaded and its features are inspected.\n",
        "2. **Preprocessing**: The target labels are one-hot encoded for multiclass classification. Features are normalized using standard scaling to improve model performance.\n",
        "3. **Data Splitting**: The data is split into training and test sets, stratified by class to ensure balanced representation.\n",
        "4. **Model Building**: A simple feedforward neural network is constructed using TensorFlow/Keras, with one hidden layer and a softmax output for multiclass classification.\n",
        "5. **Training**: The model is trained for 18 epochs, and training loss is visualized to monitor learning progress.\n",
        "6. **Prediction & Evaluation**: Predictions are made on the test set, and the modelâ€™s performance is evaluated using a confusion matrix and accuracy score.\n",
        "\n",
        "This notebook helps learners understand the full workflow of preparing data, building and training a neural network for multiclass classification, and evaluating results using visual tools."
      ],
      "metadata": {
        "id": "PtlIJPTvdz-5"
      },
      "id": "PtlIJPTvdz-5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "248ee82b",
      "metadata": {
        "id": "248ee82b"
      },
      "outputs": [],
      "source": [
        "# Import the wine dataset from sklearn\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# Load the dataset into a variable\n",
        "dataset = load_wine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55770dc7",
      "metadata": {
        "collapsed": true,
        "id": "55770dc7"
      },
      "outputs": [],
      "source": [
        "# Display the dataset dictionary to inspect its contents\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10edc28",
      "metadata": {
        "collapsed": true,
        "id": "b10edc28"
      },
      "outputs": [],
      "source": [
        "# Show the feature names in the dataset\n",
        "dataset['feature_names']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4adcd6cb",
      "metadata": {
        "id": "4adcd6cb"
      },
      "outputs": [],
      "source": [
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "X = dataset['data']\n",
        "\n",
        "# Assign the feature data to X and one-hot encode the target labels\n",
        "y = pd.get_dummies(dataset[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219216af",
      "metadata": {
        "collapsed": true,
        "id": "219216af"
      },
      "outputs": [],
      "source": [
        "# Print the type and shape of the feature matrix X\n",
        "print(type(X), X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69986241",
      "metadata": {
        "collapsed": true,
        "id": "69986241"
      },
      "outputs": [],
      "source": [
        "# Print the type and shape of the one-hot encoded target y\n",
        "print(type(y), y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f65c786a",
      "metadata": {
        "id": "f65c786a"
      },
      "outputs": [],
      "source": [
        "# Import StandardScaler for feature normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fit the scaler to X and transform X to have zero mean and unit variance\n",
        "scaler = StandardScaler().fit(X)\n",
        "X_ = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd83aeb",
      "metadata": {
        "collapsed": true,
        "id": "4fd83aeb"
      },
      "outputs": [],
      "source": [
        "# Print the mean values per column after scaling\n",
        "print(\"mean values per column:\\n\", X_.mean(axis=-2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342440b8",
      "metadata": {
        "collapsed": true,
        "id": "342440b8"
      },
      "outputs": [],
      "source": [
        "# Print the standard deviation values per column after scaling\n",
        "print(\"std  values per column:\\n\", X_.std(axis=-2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306fd652",
      "metadata": {
        "collapsed": true,
        "id": "306fd652"
      },
      "outputs": [],
      "source": [
        "# Import train_test_split to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, y ,test_size=0.2,\n",
        "                                                    random_state=0,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dc7308",
      "metadata": {
        "collapsed": true,
        "id": "f3dc7308"
      },
      "outputs": [],
      "source": [
        "# Print the shapes of the train and test splits for features and targets\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3656721a",
      "metadata": {
        "collapsed": true,
        "id": "3656721a"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(2)\n",
        "from tensorflow import keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c214ff85",
      "metadata": {
        "id": "c214ff85"
      },
      "outputs": [],
      "source": [
        "# Define a function to create the neural network model\n",
        "def create_model(input_shape):\n",
        "    # Input layer\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Hidden layer with 16 units and ReLU activation\n",
        "    hidden = keras.layers.Dense(16, activation=\"relu\")(inputs)\n",
        "    #hidden_layer = keras.layers.Dense(32, activation=\"relu\")(hidden_layer)\n",
        "\n",
        "    # Output layer with 3 units (for 3 classes) and softmax activation\n",
        "    outputs = keras.layers.Dense(3, activation=\"softmax\")(hidden)\n",
        "\n",
        "    # Create the model object\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0688045d",
      "metadata": {
        "collapsed": true,
        "id": "0688045d"
      },
      "outputs": [],
      "source": [
        "# Create the model using the training data shape\n",
        "model = create_model((X_train.shape[1],))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5daf2e28",
      "metadata": {
        "collapsed": true,
        "id": "5daf2e28"
      },
      "outputs": [],
      "source": [
        "# Display the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64122c8d",
      "metadata": {
        "id": "64122c8d"
      },
      "outputs": [],
      "source": [
        "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
        "model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83408f6b",
      "metadata": {
        "collapsed": true,
        "id": "83408f6b"
      },
      "outputs": [],
      "source": [
        "# Train the model on the training data for 18 epochs\n",
        "history = model.fit(X_train, y_train, epochs=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725cf7e9",
      "metadata": {
        "collapsed": true,
        "id": "725cf7e9"
      },
      "outputs": [],
      "source": [
        "# Import seaborn for plotting\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot the training loss over epochs\n",
        "sns.lineplot(x=history.epoch, y=history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3607ffbf",
      "metadata": {
        "collapsed": true,
        "id": "3607ffbf"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Create a DataFrame for the predictions\n",
        "prediction = pd.DataFrame(y_pred, columns=y.columns)\n",
        "\n",
        "# Display the predictions\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "258a4cec",
      "metadata": {
        "collapsed": true,
        "id": "258a4cec"
      },
      "outputs": [],
      "source": [
        "# Get the predicted species by finding the class with the highest probability\n",
        "predicted_species = prediction.idxmax(axis=\"columns\")\n",
        "predicted_species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e48ecc",
      "metadata": {
        "collapsed": true,
        "id": "11e48ecc"
      },
      "outputs": [],
      "source": [
        "# Import confusion_matrix and accuracy_score for model evaluation\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Get the true species from the test set\n",
        "true_species = y_test.idxmax(axis=\"columns\")\n",
        "\n",
        "# Compute the confusion matrix\n",
        "matrix = confusion_matrix(true_species, predicted_species)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9cd211",
      "metadata": {
        "collapsed": true,
        "id": "4f9cd211"
      },
      "outputs": [],
      "source": [
        "# Calculate and print the accuracy of the model\n",
        "accuracy_score(true_species, predicted_species)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}