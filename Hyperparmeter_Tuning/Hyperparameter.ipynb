{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Artificial Neural Network Implementation with Hyperparameter Tuning\n",
    "This notebook demonstrates how to build and tune a neural network for customer churn prediction.\n"
   ],
   "id": "49248e6f69e09c43"
  },
  {
   "cell_type": "markdown",
   "id": "ac9a909c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Part 1 - Data Preprocessing\n",
    "We'll start by importing necessary libraries and preparing our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076de20a",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "Import necessary Python libraries for data manipulation, visualization, and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Importing Machine Learning Libraries\n",
    "Import specific libraries for model training, preprocessing, and evaluation.\n"
   ],
   "id": "d41bc3c1926340ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3208f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Importing Deep Learning Libraries\n",
    "Import TensorFlow and related libraries for building neural networks.\n"
   ],
   "id": "b2575dbe51ad0c03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from scikeras.wrappers import KerasClassifier\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading and Initial Data Processing\n",
    "Load the dataset and select relevant features.\n"
   ],
   "id": "7174d24c59df6ea4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Handling Categorical Variables\n",
    "Convert categorical variables (Geography and Gender) into dummy variables.\n"
   ],
   "id": "6893f87bc37dac3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d100cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686caf3",
   "metadata": {},
   "source": [
    "### Combining Processed Features\n",
    "Concatenate the dummy variables with the main feature set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd005e",
   "metadata": {},
   "outputs": [],
   "source": "X=pd.concat([X,geography,gender],axis=1)\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature Cleanup\n",
    "Remove original categorical columns after creating dummy variables.\n"
   ],
   "id": "58a61b3388078ddf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db402bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Splitting\n",
    "Split the data into training and testing sets.\n"
   ],
   "id": "6b823d3c358fb5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature Scaling\n",
    "Standardize the features to have zero mean and unit variance.\n"
   ],
   "id": "5079beae72250daf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb79831",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 2 - Model Creation and Hyperparameter Tuning\n",
    "Define the model architecture and setup hyperparameter tuning.\n"
   ],
   "id": "4b65d1b4f8875ced"
  },
  {
   "cell_type": "markdown",
   "id": "7041b149",
   "metadata": {},
   "source": [
    "### Model Architecture Definition\n",
    "Define a function to create the neural network with configurable layers and activation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfaf1c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_model(layers_list, activation, n_features):\n",
    "    \"\"\"\n",
    "    layers_list : e.g. [40, 20]  -> two hidden layers: 40 neurons then 20 neurons\n",
    "    activation  : e.g. \"relu\" or \"sigmoid\" for hidden layers\n",
    "    n_features  : number of input features (X_train.shape[1])\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1) Tell Keras the input size (modern way: an explicit Input layer)\n",
    "    model.add(layers.Input(shape=(n_features,)))\n",
    "\n",
    "    # 2) Hidden layers (loop through your list)\n",
    "    for nodes in layers_list:\n",
    "        model.add(layers.Dense(nodes))  # Dense = fully-connected layer\n",
    "        model.add(layers.Activation(activation))  # your chosen nonlinearity\n",
    "        model.add(layers.Dropout(0.3))  # turn off 30% units (reduces overfitting)\n",
    "\n",
    "    # 3) Output layer for binary classification (one probability)\n",
    "    model.add(layers.Dense(1, kernel_initializer= 'glorot_uniform', activation=\"sigmoid\"))\n",
    "\n",
    "    # 4) Training setup: optimizer, loss, metric\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting up the Classifier\n",
    "Create a KerasClassifier wrapper for use with scikit-learn's GridSearchCV.\n"
   ],
   "id": "29328bea4161286d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b173f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(\n",
    "    model=create_model,\n",
    "    n_features=X_train.shape[1],  # passed into your function\n",
    "    verbose=0,\n",
    ")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Defining Hyperparameter Grid\n",
    "Define the different combinations of hyperparameters to try.\n"
   ],
   "id": "33cddb4a19a1a8f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda61a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates\n",
    "layers_candidates = [[20], [40, 20], [45, 30, 15]]\n",
    "activations = ['sigmoid', 'relu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cf886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Note the model__ prefix for arguments to create_model\n",
    "param_grid = {\n",
    "    \"model__layers_list\": layers_candidates,\n",
    "    \"model__activation\": activations,\n",
    "    \"batch_size\": [128, 256],\n",
    "    \"epochs\": [30],\n",
    "}\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting up Grid Search\n",
    "Initialize GridSearchCV with our model and parameter grid.\n"
   ],
   "id": "66ace77e08778b40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d82a19",
   "metadata": {},
   "outputs": [],
   "source": "grid = GridSearchCV(estimator=clf, param_grid=param_grid,cv=5)\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Training the Model\n",
    "Perform grid search to find the best hyperparameters.\n"
   ],
   "id": "1d6e69d9e377aaf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e621153",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid_result.best_params_)\n",
    "print(\"Best score:\", grid_result.best_score_)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation\n",
    "Evaluate the best model on the test set.\n"
   ],
   "id": "4f9c6f2a59a1999"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "best_clf = grid.best_estimator_\n",
    "test_acc = best_clf.score(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Making Predictions\n",
    "Generate predictions using the best model.\n"
   ],
   "id": "fbd8c805c0edc393"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83910b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = grid.predict(X_test)\n",
    "y_pred = (pred_y > 0.5).astype(int)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating Confusion Matrix\n",
    "Generate and display the confusion matrix.\n"
   ],
   "id": "66c596c5a6eea1ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Calculate Final Accuracy\n",
    "Compute and display the final accuracy score.\n"
   ],
   "id": "50345e577715fce9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7743e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy:\", score)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing Results\n",
    "Create a heatmap visualization of the confusion matrix.\n"
   ],
   "id": "8a6d5993bb210bf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix (Accuracy = {score:.2f})')\n",
    "plt.show()\n"
   ],
   "id": "f15121fc2cc1ff7b"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
